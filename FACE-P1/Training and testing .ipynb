{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd5e7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb 17 13:11:12 2023\n",
    "\n",
    "@author: Debra Hogue\n",
    "\n",
    "Modified RankNet by Lv et al. to use Tensorflow not Pytorch\n",
    "and added additional comments to explain methods\n",
    "\n",
    "Paper: Simultaneously Localize, Segment and Rank the Camouflaged Objects by Lv et al.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import activations, layers, losses\n",
    "import numpy as np\n",
    "import os, argparse\n",
    "from datetime import datetime\n",
    "from Attention.ResNet_models import Generator\n",
    "from data import get_loader\n",
    "from utils import adjust_lr, AvgMeter\n",
    "from scipy import misc\n",
    "import cv2\n",
    "from data import test_dataset\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import cv2\n",
    "import tensorflow.keras.applications.resnet50 as models # instantiates the ResNet50 architecture \n",
    "\n",
    "from utils import l2_regularisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203e9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--epoch', type=int, default=1, help='epoch number')\n",
    "# parser.add_argument('--lr_gen', type=float, default=2.5e-5, help='learning rate for generator')\n",
    "# parser.add_argument('--batchsize', type=int, default=2, help='training batch size')\n",
    "# parser.add_argument('--trainsize', type=int, default=480, help='training dataset size')\n",
    "# parser.add_argument('--decay_rate', type=float, default=0.9, help='decay rate of learning rate')\n",
    "# parser.add_argument('--decay_epoch', type=int, default=40, help='every n epochs decay learning rate')\n",
    "# parser.add_argument('--feat_channel', type=int, default=32, help='reduced channel of saliency feat')\n",
    "# opt = parser.parse_args()\n",
    "# print('Generator Learning Rate: {}'.format(opt.lr_gen))\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8744bfe3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "test\n",
      "Tensor(\"loss_function/mean_squared_error/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"loss_function/Mean_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"loss_function/Mean_3:0\", shape=(), dtype=float32)\n",
      "test\n",
      "Tensor(\"loss_function/mean_squared_error/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"loss_function/Mean_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"loss_function/Mean_3:0\", shape=(), dtype=float32)\n",
      "1000/1000 [==============================] - 554s 535ms/step - loss: 1.9554\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 1.7171\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 1.5472\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 1.4257\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 1.3509\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 1.2676\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 1.2139\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 1.1615\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 1.1205\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 1.0907\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 1.0688\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 1.0326\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 1.0097\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 0.9906\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 0.9717\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 528s 527ms/step - loss: 0.9484\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.9379\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.9137\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.8895\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 0.8776\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.8668\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 529s 528ms/step - loss: 0.8410\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.8323\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.8180\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 0.8091\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 0.7873\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.7912\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 531s 530ms/step - loss: 0.7671\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 528s 527ms/step - loss: 0.7587\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.7465\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.7423\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.7368\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 536s 536ms/step - loss: 0.7255\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.7152\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.7110\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.7014\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 0.6889\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 0.6868\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.6808\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.6771\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 0.6667\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 0.6638\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.6540\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.6519\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 0.6449\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 0.6517\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 0.6431\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 530s 529ms/step - loss: 0.6315\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 0.6234\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 0.6187\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.6374\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 529s 528ms/step - loss: 0.6259\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.6067\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 528s 527ms/step - loss: 0.6020\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.5975\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 0.6021\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.5969\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 529s 528ms/step - loss: 0.6061\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.5970\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.5849\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.5809\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.5826\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.5778\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 0.5754\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 0.5779\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 0.5725\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.5659\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 0.5626\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.5686\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.5663\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 0.5580\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 0.5526\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 0.5425\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.5464\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 533s 532ms/step - loss: 0.5498\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 0.5438\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.5451\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 529s 528ms/step - loss: 0.5394\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.5383\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.5353\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 531s 530ms/step - loss: 0.5558\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 0.5412\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.5266\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.5285\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.5222\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 0.5311\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 0.5295\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 528s 528ms/step - loss: 0.5215\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.5163\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.5133\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 0.5244\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.5247\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.5141\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.5075\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.5082\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 0.5045\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 0.5112\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 529s 528ms/step - loss: 0.5010\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 530s 529ms/step - loss: 0.5068\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 0.5025\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build models\n",
    "generator = Generator(channel=32)\n",
    "\n",
    "\n",
    "# generator_params = generator.parameters()\n",
    "# generator_optimizer = tf.optimizers.Adam(generator_params, opt.lr_gen)\n",
    "\n",
    "\n",
    "image_root = './dataset/train/Imgs/'\n",
    "gt_root = './dataset/train/GT/'\n",
    "fix_root = './dataset/train/Fix/'\n",
    "\n",
    "# train_loader = get_loader(image_root, gt_root, fix_root,batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
    "# total_step = len(train_loader)\n",
    "\n",
    "CE = losses.BinaryCrossentropy(from_logits=True)\n",
    "mse_loss = losses.MeanSquaredError()\n",
    "size_rates = [0.75,1,1.25]  # multi-scale training\n",
    "\n",
    "def structure_loss(pred, mask):\n",
    "    padded = tf.pad(mask,tf.constant([[0,0],[15,15],[15,15],[0,0]]))\n",
    "    pooled =tf.nn.avg_pool2d(padded, ksize=31, strides=1, padding=\"VALID\")\n",
    "    weit  = 1+5*tf.abs(pooled-mask)\n",
    "    weit = tf.squeeze(weit)\n",
    "    wbce= tf.nn.sigmoid_cross_entropy_with_logits(mask,pred)\n",
    "   \n",
    "    wbce= tf.math.reduce_mean(wbce)\n",
    "    wbce  = tf.math.reduce_sum((weit*wbce),axis=[1,2]) /tf.reduce_sum(weit,axis=[1,2])\n",
    "    mask =tf.squeeze(mask)\n",
    "    pred  = tf.math.sigmoid(pred)\n",
    "    pred = tf.squeeze(pred)\n",
    "    inter = tf.math.reduce_sum((pred*mask)*weit,axis=[1,2])\n",
    "    union = tf.math.reduce_sum((pred+mask)*weit, axis=[1,2])\n",
    "    wiou  = 1-(inter+1)/(union-inter+1)\n",
    "    return tf.math.reduce_mean(wbce+wiou)\n",
    "\n",
    "\n",
    "        \n",
    "             \n",
    "def loss_function(y_true,y_pred):\n",
    "    gts, fixs = tf.unstack(y_true,2,0)\n",
    "    gts, _ = tf.split(gts, [1,2], 3)\n",
    "    fixs, _ = tf.split(fixs, [1,2], 3)\n",
    "    fix_pred, cod_pred1, cod_pred2 = tf.unstack(y_pred,num=3,axis=0)\n",
    "    fix_loss = mse_loss(tf.keras.activations.sigmoid(fix_pred),fixs)\n",
    "    cod_loss1 = structure_loss(cod_pred1, gts)\n",
    "    cod_loss2 = structure_loss(cod_pred2, gts)\n",
    "    test= fix_loss + cod_loss1 + cod_loss2\n",
    "    print(\"test\")\n",
    "    print(fix_loss)\n",
    "    print(cod_loss1)\n",
    "    print(cod_loss2)\n",
    "    return  fix_loss + cod_loss1 + cod_loss2\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, profile_batch='10, 15')\n",
    "    \n",
    "    op= tf.keras.optimizers.Adam(learning_rate=2.5e-5, name='Adam')\n",
    "    \n",
    "    generator.compile(optimizer=op, loss=loss_function)\n",
    "    \n",
    "    \n",
    "    data = get_loader(image_root, gt_root, fix_root, 480, 2)\n",
    "    \n",
    "  \n",
    "    generator.fit(x=data,batch_size=2, epochs=epoch, verbose='auto' , callbacks=[tensorboard_callback])\n",
    "     \n",
    "    save_path = 'models/Resnet/'\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    dataset_path = './dataset/test/'\n",
    "\n",
    "\n",
    "\n",
    "    test_datasets = ['Mine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "print(\"Generator is build\")\n",
    "generator.save(\"results/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82f8798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/test/Mine/Imgs/\n",
      "['An_invisibility_cloak_using_optical_camouflage_by_Susumu_Tachi.jpg', 'many things.jpg', 'Peacock_Flounder_Bothus_mancus_in_Kona1.jpg', 'Peacock_Flounder_Bothus_mancus_in_Kona2.jpg', 'Peacock_Flounder_Bothus_mancus_in_Kona3.jpg', 'Peacock_Flounder_Bothus_mancus_in_Kona4.jpg', 'Smallthing big.jpg', 'Untitle.jpg']\n",
      "8\n",
      "0\n",
      "./results/ResNet50/Mine/An_invisibility_cloak_using_optical_camouflage_by_Susumu_Tachi.png\n",
      "\n",
      "1\n",
      "./results/ResNet50/Mine/Peacock_Flounder_Bothus_mancus_in_Kona1.png\n",
      "\n",
      "2\n",
      "./results/ResNet50/Mine/Peacock_Flounder_Bothus_mancus_in_Kona2.png\n",
      "\n",
      "3\n",
      "./results/ResNet50/Mine/Peacock_Flounder_Bothus_mancus_in_Kona3.png\n",
      "\n",
      "4\n",
      "./results/ResNet50/Mine/Peacock_Flounder_Bothus_mancus_in_Kona4.png\n",
      "\n",
      "5\n",
      "./results/ResNet50/Mine/Smallthing big.png\n",
      "\n",
      "6\n",
      "./results/ResNet50/Mine/Untitle.png\n",
      "\n",
      "7\n",
      "./results/ResNet50/Mine/many things.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in test_datasets:\n",
    "    save_path = './results/ResNet50/' + dataset + '/'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    image_root = dataset_path + dataset + '/Imgs/'\n",
    "    test_loader = test_dataset(image_root, 480)\n",
    "\n",
    "    for i in range(test_loader.size):\n",
    "        print(i)\n",
    "        image, HH, WW, name = test_loader.load_data()\n",
    "        ans = generator(image)\n",
    "        _,generator_pred, _  = tf.unstack(ans,num=3,axis=0)\n",
    "        res = generator_pred\n",
    "        res = tf.image.resize(res, size=tf.constant([WW,HH]), method=tf.image.ResizeMethod.BILINEAR)\n",
    "        res = tf.math.sigmoid(res).numpy().squeeze()\n",
    "        res = 255*(res - res.min()) / (res.max() - res.min() + 1e-8)\n",
    "        print(save_path+name)\n",
    "        cv2.imwrite(save_path+name, res)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4575b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#generator2 = Generator(channel=32)\n",
    "generator2 =  tf.keras.models.load_model('./results/model', custom_objects={'loss_function': loss_function})\n",
    "for dataset in test_datasets:\n",
    "    save_path = './results/small/' + dataset + '/'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    image_root = dataset_path + dataset + '/Imgs/'\n",
    "    test_loader = test_dataset(image_root, 480)\n",
    "\n",
    "    for i in range(test_loader.size):\n",
    "        print(i)\n",
    "        image, HH, WW, name = test_loader.load_data()\n",
    "        ans = generator2(image)\n",
    "        _,generator_pred, _  = tf.unstack(ans,num=3,axis=0)\n",
    "        res = generator_pred\n",
    "        res = tf.image.resize(res, size=tf.constant([WW,HH]), method=tf.image.ResizeMethod.BILINEAR)\n",
    "        res = tf.math.sigmoid(res).numpy().squeeze()\n",
    "        res = 255*(res - res.min()) / (res.max() - res.min() + 1e-8)\n",
    "        print(save_path+name)\n",
    "        cv2.imwrite(save_path+name, res)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdb00c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
