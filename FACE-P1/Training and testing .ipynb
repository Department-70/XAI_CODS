{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd5e7f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Quadro RTX 3000, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb 17 13:11:12 2023\n",
    "\n",
    "@author: Debra Hogue\n",
    "\n",
    "Modified RankNet by Lv et al. to use Tensorflow not Pytorch\n",
    "and added additional comments to explain methods\n",
    "\n",
    "Paper: Simultaneously Localize, Segment and Rank the Camouflaged Objects by Lv et al.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import activations, layers, losses\n",
    "import numpy as np\n",
    "import os, argparse\n",
    "from datetime import datetime\n",
    "from Attention.ResNet_models import Generator\n",
    "from data import get_loader\n",
    "from utils import adjust_lr, AvgMeter\n",
    "from scipy import misc\n",
    "import cv2\n",
    "from data import test_dataset\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import cv2\n",
    "import tensorflow.keras.applications.resnet50 as models # instantiates the ResNet50 architecture \n",
    "\n",
    "from utils import l2_regularisation\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=5632)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "tf.config.optimizer.set_experimental_options({\"Memory optimizer\": True, \"Layout optimizer\": True})\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203e9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--epoch', type=int, default=1, help='epoch number')\n",
    "# parser.add_argument('--lr_gen', type=float, default=2.5e-5, help='learning rate for generator')\n",
    "# parser.add_argument('--batchsize', type=int, default=2, help='training batch size')\n",
    "# parser.add_argument('--trainsize', type=int, default=480, help='training dataset size')\n",
    "# parser.add_argument('--decay_rate', type=float, default=0.9, help='decay rate of learning rate')\n",
    "# parser.add_argument('--decay_epoch', type=int, default=40, help='every n epochs decay learning rate')\n",
    "# parser.add_argument('--feat_channel', type=int, default=32, help='reduced channel of saliency feat')\n",
    "# opt = parser.parse_args()\n",
    "# print('Generator Learning Rate: {}'.format(opt.lr_gen))\n",
    "epoch = 1\n",
    "decay_rate = 0.97\n",
    "decay_epoch = 65\n",
    "batchsize = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8744bfe3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# build models\n",
    "generator = Generator(channel=32)\n",
    "\n",
    "\n",
    "# generator_params = generator.parameters()\n",
    "# generator_optimizer = tf.optimizers.Adam(generator_params, opt.lr_gen)\n",
    "\n",
    "\n",
    "image_root = '../dataset/train/Imgs/'\n",
    "gt_root = '../dataset/train/GT/'\n",
    "fix_root = '../dataset/train/Fix/'\n",
    "\n",
    "# train_loader = get_loader(image_root, gt_root, fix_root,batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
    "# total_step = len(train_loader)\n",
    "\n",
    "CE = losses.BinaryCrossentropy(from_logits=True)\n",
    "mse_loss = losses.MeanSquaredError()\n",
    "size_rates = [0.75,1,1.25]  # multi-scale training\n",
    "\n",
    "def structure_loss(pred, mask):\n",
    "    padded = tf.pad(mask,tf.constant([[0,0],[15,15],[15,15],[0,0]]))\n",
    "    pooled =tf.nn.avg_pool2d(padded, ksize=31, strides=1, padding=\"VALID\")\n",
    "    weit  = 1+5*tf.abs(pooled-mask)\n",
    "    weit = tf.squeeze(weit,[3])\n",
    "    wbce= tf.nn.sigmoid_cross_entropy_with_logits(mask,pred)\n",
    "   \n",
    "    wbce= tf.math.reduce_mean(wbce)\n",
    "    wbce  = tf.math.reduce_sum((weit*wbce),axis=[1,2]) /tf.reduce_sum(weit,axis=[1,2])\n",
    "    mask =tf.squeeze(mask,[3])\n",
    "    pred  = tf.math.sigmoid(pred)\n",
    "    pred = tf.squeeze(pred,[3])\n",
    "    inter = tf.math.reduce_sum((pred*mask)*weit,axis=[1,2])\n",
    "    union = tf.math.reduce_sum((pred+mask)*weit, axis=[1,2])\n",
    "    wiou  = 1-(inter+1)/(union-inter+1)\n",
    "    return tf.math.reduce_mean(wbce+wiou)\n",
    "\n",
    "\n",
    "        \n",
    "             \n",
    "def loss_function(y_true,y_pred):\n",
    "    gts, fixs = tf.unstack(y_true,2,0)\n",
    "    gts, _ = tf.split(gts, [1,2], 3)\n",
    "    fixs, _ = tf.split(fixs, [1,2], 3)\n",
    "    fix_pred, cod_pred1, cod_pred2 = tf.unstack(y_pred,num=3,axis=0)\n",
    "    fix_loss = mse_loss(tf.keras.activations.sigmoid(fix_pred),fixs)\n",
    "    cod_loss1 = structure_loss(cod_pred1, gts)\n",
    "    cod_loss2 = structure_loss(cod_pred2, gts)\n",
    "    test= fix_loss + cod_loss1 + cod_loss2\n",
    "    return  fix_loss + cod_loss1 + cod_loss2\n",
    "    \n",
    "def on_epoch_end( epoch, lr):\n",
    "    decay = decay_rate ** (epoch // decay_epoch)\n",
    "    new_lr = lr * decay\n",
    "    print(\"\\nEpoch: {}. Reducing Learning Rate from {} to {}\".format(epoch, lr, new_lr))\n",
    "    return new_lr\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a471a068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102967424/102967424 [==============================] - 2s 0us/step\n",
      "\n",
      "Epoch: 0. Reducing Learning Rate from 2.499999936844688e-05 to 2.499999936844688e-05\n",
      "2001/2001 [==============================] - 1301s 633ms/step - loss: 1.8322 - lr: 2.5000e-05\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, profile_batch='10, 15')\n",
    "    \n",
    "    op= tf.keras.optimizers.Adam(learning_rate=2.5e-5, name='Adam')\n",
    "    \n",
    "    generator.compile(optimizer=op, loss=loss_function, run_eagerly=False)\n",
    "    \n",
    "    \n",
    "    data = get_loader(image_root, gt_root, fix_root, 480, batchsize, size_rates)\n",
    "    print(len(data))\n",
    "    generator.fit(x=data,batch_size=batchsize, epochs=epoch, verbose='auto' , callbacks=[tensorboard_callback, tf.keras.callbacks.LearningRateScheduler(on_epoch_end)])\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3912d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = 'models/Resnet/'\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_path = '../dataset/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e19a3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator is build\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.relu.ReLU object at 0x000002574AE7DCD0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.up_sampling2d.UpSampling2D object at 0x000002574AE7DF70>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.up_sampling2d.UpSampling2D object at 0x000002574AED9340>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000002574AED96D0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.relu.ReLU object at 0x000002574AED9C40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.up_sampling2d.UpSampling2D object at 0x000002574AF22460>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000002574AF22670>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.relu.ReLU object at 0x000002575119B880>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.up_sampling2d.UpSampling2D object at 0x000002575119BA90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.up_sampling2d.UpSampling2D object at 0x00000257511AB0A0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000257511AB2B0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <Attention.ResNet_models.Classifier_Module object at 0x00000257511AB640>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <Attention.ResNet_models.Classifier_Module object at 0x00000257512AF100>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x00000257511ABFA0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.conv2d.Conv2D object at 0x00000257511B1190>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x00000257511B1700>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.conv2d.Conv2D object at 0x00000257511B1910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x00000257511B1E80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.conv2d.Conv2D object at 0x00000257511B1FD0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x00000257511B7640>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.conv2d.Conv2D object at 0x00000257511B7850>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x00000257514F5760>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.conv2d.Conv2D object at 0x00000257514F5910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x00000257514F5EB0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.conv2d.Conv2D object at 0x00000257514FB100>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x00000257514FB6A0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.conv2d.Conv2D object at 0x00000257514FB8B0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x00000257514FBE50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.conv2d.Conv2D object at 0x00000257514FBFA0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as fix_feat_decoder_layer_call_fn, fix_feat_decoder_layer_call_and_return_conditional_losses, saliency_feat_decoder_layer_call_fn, saliency_feat_decoder_layer_call_and_return_conditional_losses, ha_layer_call_fn while saving (showing 5 of 168). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/model\\assets\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "print(\"Generator is build\")\n",
    "generator.save(\"results/model\")\n",
    "#generator.save(\"results/model2\",save_format=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "057edf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets = ['Mine', 'CAMO']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f82f8798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(i)\n\u001b[0;32m     12\u001b[0m image, HH, WW, name \u001b[39m=\u001b[39m test_loader\u001b[39m.\u001b[39mload_data()\n\u001b[1;32m---> 13\u001b[0m ans \u001b[39m=\u001b[39m generator(image)\n\u001b[0;32m     14\u001b[0m fix_image,generator_pred, img2  \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39munstack(ans,num\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     17\u001b[0m res \u001b[39m=\u001b[39m generator_pred\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\engine\\training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    555\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 557\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\Documents\\GitHub\\XAI_CODS\\FACE-P1\\Attention\\ResNet_models.py:36\u001b[0m, in \u001b[0;36mGenerator.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 36\u001b[0m     fix_pred, cod_pred1, cod_pred2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msal_encoder(x)\n\u001b[0;32m     37\u001b[0m     shape \u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mslice(tf\u001b[39m.\u001b[39mshape(x), [\u001b[39m1\u001b[39m],[\u001b[39m2\u001b[39m])\n\u001b[0;32m     38\u001b[0m     fix_pred \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mresize(fix_pred, size\u001b[39m=\u001b[39mshape, method\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mResizeMethod\u001b[39m.\u001b[39mBILINEAR)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\Documents\\GitHub\\XAI_CODS\\FACE-P1\\Attention\\ResNet_models.py:384\u001b[0m, in \u001b[0;36mSaliency_feat_encoder.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, x ):\n\u001b[1;32m--> 384\u001b[0m     x1,x2,x3,x4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mB1_res(x)\n\u001b[0;32m    386\u001b[0m     fix_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcod_dec(x1,x2,x3,x4)\n\u001b[0;32m    387\u001b[0m     init_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msal_dec(x1,x2,x3,x4)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\engine\\training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    555\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 557\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\engine\\functional.py:510\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    493\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \n\u001b[0;32m    495\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\engine\\functional.py:667\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    664\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    666\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 667\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mlayer(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    669\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    671\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[0;32m    672\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:304\u001b[0m, in \u001b[0;36mConv.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    300\u001b[0m             outputs \u001b[39m=\u001b[39m conv_utils\u001b[39m.\u001b[39msqueeze_batch_dims(\n\u001b[0;32m    301\u001b[0m                 outputs, _apply_fn, inner_rank\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrank \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    302\u001b[0m             )\n\u001b[0;32m    303\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m             outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mbias_add(\n\u001b[0;32m    305\u001b[0m                 outputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tf_data_format\n\u001b[0;32m    306\u001b[0m             )\n\u001b[0;32m    308\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    309\u001b[0m     \u001b[39m# Infer the static output shape:\u001b[39;00m\n\u001b[0;32m    310\u001b[0m     out_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_output_shape(input_shape)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:3554\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   3551\u001b[0m   value \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(value, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3552\u001b[0m   bias \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(bias, dtype\u001b[39m=\u001b[39mvalue\u001b[39m.\u001b[39mdtype, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 3554\u001b[0m \u001b[39mreturn\u001b[39;00m gen_nn_ops\u001b[39m.\u001b[39;49mbias_add(value, bias, data_format\u001b[39m=\u001b[39;49mdata_format, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:857\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m    855\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m bias_add_eager_fallback(\n\u001b[0;32m    858\u001b[0m       value, bias, data_format\u001b[39m=\u001b[39;49mdata_format, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[0;32m    859\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[0;32m    860\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:884\u001b[0m, in \u001b[0;36mbias_add_eager_fallback\u001b[1;34m(value, bias, data_format, name, ctx)\u001b[0m\n\u001b[0;32m    882\u001b[0m   data_format \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNHWC\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m data_format \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_str(data_format, \u001b[39m\"\u001b[39m\u001b[39mdata_format\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 884\u001b[0m _attr_T, _inputs_T \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49margs_to_matching_eager([value, bias], ctx, [_dtypes\u001b[39m.\u001b[39;49mfloat32, _dtypes\u001b[39m.\u001b[39;49mfloat64, _dtypes\u001b[39m.\u001b[39;49mint32, _dtypes\u001b[39m.\u001b[39;49muint8, _dtypes\u001b[39m.\u001b[39;49mint16, _dtypes\u001b[39m.\u001b[39;49mint8, _dtypes\u001b[39m.\u001b[39;49mcomplex64, _dtypes\u001b[39m.\u001b[39;49mint64, _dtypes\u001b[39m.\u001b[39;49mqint8, _dtypes\u001b[39m.\u001b[39;49mquint8, _dtypes\u001b[39m.\u001b[39;49mqint32, _dtypes\u001b[39m.\u001b[39;49mbfloat16, _dtypes\u001b[39m.\u001b[39;49muint16, _dtypes\u001b[39m.\u001b[39;49mcomplex128, _dtypes\u001b[39m.\u001b[39;49mhalf, _dtypes\u001b[39m.\u001b[39;49muint32, _dtypes\u001b[39m.\u001b[39;49muint64, ])\n\u001b[0;32m    885\u001b[0m (value, bias) \u001b[39m=\u001b[39m _inputs_T\n\u001b[0;32m    886\u001b[0m _inputs_flat \u001b[39m=\u001b[39m [value, bias]\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:271\u001b[0m, in \u001b[0;36margs_to_matching_eager\u001b[1;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[0;32m    269\u001b[0m       dtype \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    270\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m   ret \u001b[39m=\u001b[39m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t, dtype, ctx\u001b[39m=\u001b[39mctx) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m l]\n\u001b[0;32m    273\u001b[0m \u001b[39m# TODO(slebedev): consider removing this as it leaks a Keras concept.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    275\u001b[0m keras_symbolic_tensors \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m ret \u001b[39mif\u001b[39;00m ops\u001b[39m.\u001b[39m_is_keras_symbolic_tensor(x)]\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:271\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    269\u001b[0m       dtype \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    270\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m   ret \u001b[39m=\u001b[39m [ops\u001b[39m.\u001b[39;49mconvert_to_tensor(t, dtype, ctx\u001b[39m=\u001b[39;49mctx) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m l]\n\u001b[0;32m    273\u001b[0m \u001b[39m# TODO(slebedev): consider removing this as it leaks a Keras concept.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    275\u001b[0m keras_symbolic_tensors \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m ret \u001b[39mif\u001b[39;00m ops\u001b[39m.\u001b[39m_is_keras_symbolic_tensor(x)]\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1629\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[0;32m   1631\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1634\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1635\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[0;32m   1637\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1638\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1640\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1641\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\mixed_precision\\autocast_variable.py:151\u001b[0m, in \u001b[0;36mAutoCastVariable._dense_var_to_tensor\u001b[1;34m(self, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype\u001b[39m.\u001b[39mis_compatible_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cast_dtype):\n\u001b[0;32m    145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    146\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIncompatible type conversion requested to type \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAutoCastVariable which is casted to type \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    148\u001b[0m             dtype\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cast_dtype\u001b[39m.\u001b[39mname\n\u001b[0;32m    149\u001b[0m         )\n\u001b[0;32m    150\u001b[0m     )\n\u001b[1;32m--> 151\u001b[0m val \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[0;32m    152\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable\u001b[39m.\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    154\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcast(val, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cast_dtype)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1492\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   1429\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1430\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[0;32m   1431\u001b[0m     value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype_hint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1432\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[0;32m   1433\u001b[0m \n\u001b[0;32m   1434\u001b[0m \u001b[39m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1490\u001b[0m \u001b[39m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[0;32m   1491\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1492\u001b[0m   \u001b[39mreturn\u001b[39;00m convert_to_tensor_v2(\n\u001b[0;32m   1493\u001b[0m       value, dtype\u001b[39m=\u001b[39;49mdtype, dtype_hint\u001b[39m=\u001b[39;49mdtype_hint, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1498\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_to_tensor_v2\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype_hint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1497\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1498\u001b[0m   \u001b[39mreturn\u001b[39;00m convert_to_tensor(\n\u001b[0;32m   1499\u001b[0m       value\u001b[39m=\u001b[39;49mvalue,\n\u001b[0;32m   1500\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1501\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1502\u001b[0m       preferred_dtype\u001b[39m=\u001b[39;49mdtype_hint,\n\u001b[0;32m   1503\u001b[0m       as_ref\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1629\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[0;32m   1631\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1634\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1635\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[0;32m   1637\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1638\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1640\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1641\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2105\u001b[0m, in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   2104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_dense_var_to_tensor\u001b[39m(var, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m-> 2105\u001b[0m   \u001b[39mreturn\u001b[39;00m var\u001b[39m.\u001b[39;49m_dense_var_to_tensor(dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1467\u001b[0m, in \u001b[0;36mBaseResourceVariable._dense_var_to_tensor\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1465\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_value()\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39minputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1466\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1467\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue()\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:582\u001b[0m, in \u001b[0;36mBaseResourceVariable.value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    580\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_value\n\u001b[0;32m    581\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mNone\u001b[39;00m, ignore_existing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 582\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_variable_op()\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:704\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    703\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    707\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    708\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m   tape\u001b[39m.\u001b[39mrecord_operation(\n\u001b[0;32m    710\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[0;32m    711\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    712\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:694\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39mif\u001b[39;00m no_copy \u001b[39mand\u001b[39;00m forward_compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2022\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m    693\u001b[0m   gen_resource_variable_ops\u001b[39m.\u001b[39mdisable_copy_on_read(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[1;32m--> 694\u001b[0m result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mread_variable_op(\n\u001b[0;32m    695\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[0;32m    696\u001b[0m _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[0;32m    697\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:524\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    523\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 524\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    525\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mReadVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, resource, \u001b[39m\"\u001b[39;49m\u001b[39mdtype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype)\n\u001b[0;32m    526\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    527\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for dataset in test_datasets:\n",
    "    save_path = './results/ResNet50/' + dataset + '/'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    image_root = dataset_path + dataset + '/Imgs/'\n",
    "    test_loader = test_dataset(image_root, 480)\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    for i in range(test_loader.size):\n",
    "        print(i)\n",
    "        image, HH, WW, name = test_loader.load_data()\n",
    "        ans = generator(image)\n",
    "        fix_image,generator_pred, img2  = tf.unstack(ans,num=3,axis=0)\n",
    "\n",
    "\n",
    "        res = generator_pred\n",
    "        res = tf.image.resize(res, size=tf.constant([WW,HH]), method=tf.image.ResizeMethod.BILINEAR)\n",
    "        res = tf.math.sigmoid(res).numpy().squeeze()\n",
    "        res = 255*(res - res.min()) / (res.max() - res.min() + 1e-8)\n",
    "        \n",
    "        \n",
    "        fix_image = tf.image.resize(fix_image, size=tf.constant([WW,HH]), method=tf.image.ResizeMethod.BILINEAR)\n",
    "        fix_image = tf.math.sigmoid(fix_image).numpy().squeeze()\n",
    "        \n",
    "        fix_image = (fix_image - fix_image.min()) / (fix_image.max() - fix_image.min() + 1e-8)\n",
    "        \n",
    "        res2 = img2\n",
    "        res2 = tf.image.resize(res2, size=tf.constant([WW,HH]), method=tf.image.ResizeMethod.BILINEAR)\n",
    "        res2 = tf.math.sigmoid(res2).numpy().squeeze()\n",
    "        res2 = (res2 - res2.min()) / (res.max() - res2.min() + 1e-8)\n",
    "        \n",
    "        #fig.add_subplot(1, 3, 1)\n",
    "        '''\n",
    "        plt.imshow(fix_image)\n",
    "        #plt.axis('off')\n",
    "        plt.title(\"First\")\n",
    "        plt.show()\n",
    "        #fig.add_subplot(1, 3, 2)\n",
    "        plt.imshow(res)\n",
    "        #plt.axis('off')\n",
    "        plt.title(\"Second\")\n",
    "        plt.show()\n",
    "        #fig.add_subplot(1, 3, 3)\n",
    "        plt.imshow(res2)\n",
    "        #plt.axis('off')\n",
    "        plt.title(\"Third\")\n",
    "        plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b4575b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4201\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   4200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 4201\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op_def_cache[\u001b[39mtype\u001b[39;49m]\n\u001b[0;32m   4202\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'StatefulPartitionedCall'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#generator2 = Generator(channel=32)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m generator2 \u001b[39m=\u001b[39m  tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39mresults/model\u001b[39;49m\u001b[39m'\u001b[39;49m, custom_objects\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mloss_function\u001b[39;49m\u001b[39m'\u001b[39;49m: loss_function})\n\u001b[0;32m      3\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m7\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m test_datasets:\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\saving\\save.py:231\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m     )\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m--> 231\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39;49mload(\n\u001b[0;32m    232\u001b[0m         filepath_str, \u001b[39mcompile\u001b[39;49m, options\n\u001b[0;32m    233\u001b[0m     )\n\u001b[0;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[39mif\u001b[39;00m h5py \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\keras\\saving\\saved_model\\load.py:141\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[0;32m    138\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\n\u001b[0;32m    139\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrying to load ShardedVariables\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m     )\n\u001b[1;32m--> 141\u001b[0m     loaded \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload_partial(\n\u001b[0;32m    142\u001b[0m         path, nodes_to_load, options\u001b[39m=\u001b[39;49moptions\n\u001b[0;32m    143\u001b[0m     )\n\u001b[0;32m    145\u001b[0m \u001b[39m# Finalize the loaded layers and remove the extra tracked dependencies.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m keras_loader\u001b[39m.\u001b[39mfinalize_objects()\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:930\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39minit_scope():\n\u001b[0;32m    929\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 930\u001b[0m     loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    931\u001b[0m                     ckpt_options, options, filters)\n\u001b[0;32m    932\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    933\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m         \u001b[39mstr\u001b[39m(err) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m You may be trying to load on a different device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfrom the computational device. Consider setting the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto the io_device such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:154\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_proto \u001b[39m=\u001b[39m object_graph_proto\n\u001b[0;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_export_dir \u001b[39m=\u001b[39m export_dir\n\u001b[0;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_functions \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 154\u001b[0m     function_deserialization\u001b[39m.\u001b[39;49mload_function_def_library(\n\u001b[0;32m    155\u001b[0m         library\u001b[39m=\u001b[39;49mmeta_graph\u001b[39m.\u001b[39;49mgraph_def\u001b[39m.\u001b[39;49mlibrary,\n\u001b[0;32m    156\u001b[0m         saved_object_graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_proto,\n\u001b[0;32m    157\u001b[0m         wrapper_function\u001b[39m=\u001b[39;49m_WrapperFunction))\n\u001b[0;32m    158\u001b[0m \u001b[39m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39m# captures.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restored_concrete_functions \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:416\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[39m# There is no need to copy all functions into the function def graph. It\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[39m# leads to a O(n^2) increase of memory when importing functions and the\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[39m# extra function definitions are a no-op since they already imported as a\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[39m# function before and passed in explicitly (due to the topologic sort\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[39m# import).\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m--> 416\u001b[0m   func_graph \u001b[39m=\u001b[39m function_def_lib\u001b[39m.\u001b[39;49mfunction_def_to_graph(\n\u001b[0;32m    417\u001b[0m       fdef,\n\u001b[0;32m    418\u001b[0m       structured_input_signature\u001b[39m=\u001b[39;49mstructured_input_signature,\n\u001b[0;32m    419\u001b[0m       structured_outputs\u001b[39m=\u001b[39;49mstructured_outputs)\n\u001b[0;32m    420\u001b[0m \u001b[39m# Restores gradients for function-call ops (not the same as ops that use\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[39m# custom gradients)\u001b[39;00m\n\u001b[0;32m    422\u001b[0m _restore_gradient_functions(func_graph, renamed_functions, loaded_gradients)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:87\u001b[0m, in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, structured_input_signature, structured_outputs, input_shapes)\u001b[0m\n\u001b[0;32m     82\u001b[0m graph_def, nested_to_flat_tensor_name \u001b[39m=\u001b[39m function_def_to_graph_def(\n\u001b[0;32m     83\u001b[0m     fdef, input_shapes)\n\u001b[0;32m     85\u001b[0m \u001b[39mwith\u001b[39;00m func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m     86\u001b[0m   \u001b[39m# Add all function nodes to the graph.\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m   importer\u001b[39m.\u001b[39;49mimport_graph_def_for_function(graph_def, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     89\u001b[0m   \u001b[39m# Initialize fields specific to FuncGraph.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[0;32m     91\u001b[0m   \u001b[39m# inputs\u001b[39;00m\n\u001b[0;32m     92\u001b[0m   input_tensor_names \u001b[39m=\u001b[39m [\n\u001b[0;32m     93\u001b[0m       nested_to_flat_tensor_name[arg\u001b[39m.\u001b[39mname] \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m fdef\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39minput_arg\n\u001b[0;32m     94\u001b[0m   ]\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py:414\u001b[0m, in \u001b[0;36mimport_graph_def_for_function\u001b[1;34m(graph_def, name)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimport_graph_def_for_function\u001b[39m(  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[0;32m    412\u001b[0m     graph_def, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    413\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Like import_graph_def but does not validate colocation constraints.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m   \u001b[39mreturn\u001b[39;00m _import_graph_def_internal(\n\u001b[0;32m    415\u001b[0m       graph_def, validate_colocation_constraints\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py:517\u001b[0m, in \u001b[0;36m_import_graph_def_internal\u001b[1;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\u001b[0m\n\u001b[0;32m    505\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mstr\u001b[39m(e))\n\u001b[0;32m    507\u001b[0m   \u001b[39m# Create _DefinedFunctions for any imported functions.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m   \u001b[39m#\u001b[39;00m\n\u001b[0;32m    509\u001b[0m   \u001b[39m# We do this by creating _DefinedFunctions directly from `graph_def`, and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m   \u001b[39m# TODO(skyewm): fetch the TF_Functions directly from the TF_Graph\u001b[39;00m\n\u001b[0;32m    515\u001b[0m   \u001b[39m# TODO(skyewm): avoid sending serialized FunctionDefs back to the TF_Graph\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m   _ProcessNewOps(graph)\n\u001b[0;32m    519\u001b[0m \u001b[39mif\u001b[39;00m graph_def\u001b[39m.\u001b[39mlibrary \u001b[39mand\u001b[39;00m graph_def\u001b[39m.\u001b[39mlibrary\u001b[39m.\u001b[39mfunction:\n\u001b[0;32m    520\u001b[0m   functions \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfrom_library(graph_def\u001b[39m.\u001b[39mlibrary)\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py:247\u001b[0m, in \u001b[0;36m_ProcessNewOps\u001b[1;34m(graph)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39m# Maps from a node to the names of the ops it's colocated with, if colocation\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[39m# is specified in the attributes.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m colocation_pairs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 247\u001b[0m \u001b[39mfor\u001b[39;00m new_op \u001b[39min\u001b[39;00m graph\u001b[39m.\u001b[39;49m_add_new_tf_operations(compute_devices\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    248\u001b[0m   original_device \u001b[39m=\u001b[39m new_op\u001b[39m.\u001b[39mdevice\n\u001b[0;32m    249\u001b[0m   new_op\u001b[39m.\u001b[39m_set_device(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3950\u001b[0m, in \u001b[0;36mGraph._add_new_tf_operations\u001b[1;34m(self, compute_devices)\u001b[0m\n\u001b[0;32m   3946\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_not_finalized()\n\u001b[0;32m   3948\u001b[0m \u001b[39m# Create all Operation objects before accessing their inputs since an op may\u001b[39;00m\n\u001b[0;32m   3949\u001b[0m \u001b[39m# be created before its inputs.\u001b[39;00m\n\u001b[1;32m-> 3950\u001b[0m new_ops \u001b[39m=\u001b[39m [\n\u001b[0;32m   3951\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_from_tf_operation(c_op, compute_device\u001b[39m=\u001b[39mcompute_devices)\n\u001b[0;32m   3952\u001b[0m     \u001b[39mfor\u001b[39;00m c_op \u001b[39min\u001b[39;00m c_api_util\u001b[39m.\u001b[39mnew_tf_operations(\u001b[39mself\u001b[39m)\n\u001b[0;32m   3953\u001b[0m ]\n\u001b[0;32m   3955\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3956\u001b[0m \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m new_ops:\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3951\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3946\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_not_finalized()\n\u001b[0;32m   3948\u001b[0m \u001b[39m# Create all Operation objects before accessing their inputs since an op may\u001b[39;00m\n\u001b[0;32m   3949\u001b[0m \u001b[39m# be created before its inputs.\u001b[39;00m\n\u001b[0;32m   3950\u001b[0m new_ops \u001b[39m=\u001b[39m [\n\u001b[1;32m-> 3951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_op_from_tf_operation(c_op, compute_device\u001b[39m=\u001b[39;49mcompute_devices)\n\u001b[0;32m   3952\u001b[0m     \u001b[39mfor\u001b[39;00m c_op \u001b[39min\u001b[39;00m c_api_util\u001b[39m.\u001b[39mnew_tf_operations(\u001b[39mself\u001b[39m)\n\u001b[0;32m   3953\u001b[0m ]\n\u001b[0;32m   3955\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3956\u001b[0m \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m new_ops:\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3833\u001b[0m, in \u001b[0;36mGraph._create_op_from_tf_operation\u001b[1;34m(self, c_op, compute_device)\u001b[0m\n\u001b[0;32m   3813\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates an `Operation` in this graph from the supplied TF_Operation.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m \n\u001b[0;32m   3815\u001b[0m \u001b[39mThis method is like create_op() except the new Operation is constructed\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3830\u001b[0m \u001b[39m  An `Operation` object.\u001b[39;00m\n\u001b[0;32m   3831\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3832\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_not_finalized()\n\u001b[1;32m-> 3833\u001b[0m ret \u001b[39m=\u001b[39m Operation\u001b[39m.\u001b[39;49m_from_c_op(c_op\u001b[39m=\u001b[39;49mc_op, g\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3834\u001b[0m \u001b[39m# If a name_scope was created with ret.name but no nodes were created in it,\u001b[39;00m\n\u001b[0;32m   3835\u001b[0m \u001b[39m# the name will still appear in _names_in_use even though the name hasn't\u001b[39;00m\n\u001b[0;32m   3836\u001b[0m \u001b[39m# been used. This is ok, just leave _names_in_use as-is in this case.\u001b[39;00m\n\u001b[0;32m   3837\u001b[0m \u001b[39m# TODO(skyewm): make the C API guarantee no name conflicts.\u001b[39;00m\n\u001b[0;32m   3838\u001b[0m name_key \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2137\u001b[0m, in \u001b[0;36mOperation._from_c_op\u001b[1;34m(cls, c_op, g)\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create an Operation from a TF_Operation.\u001b[39;00m\n\u001b[0;32m   2123\u001b[0m \n\u001b[0;32m   2124\u001b[0m \u001b[39mFor internal use only: This is useful for creating Operation for ops\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2133\u001b[0m \u001b[39m  an Operation object.\u001b[39;00m\n\u001b[0;32m   2134\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2135\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[1;32m-> 2137\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_from_c_op(c_op\u001b[39m=\u001b[39;49mc_op, g\u001b[39m=\u001b[39;49mg)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2138\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2174\u001b[0m, in \u001b[0;36mOperation._init_from_c_op\u001b[1;34m(self, c_op, g)\u001b[0m\n\u001b[0;32m   2167\u001b[0m \u001b[39m# Gradient function for this op. There are three ways to specify gradient\u001b[39;00m\n\u001b[0;32m   2168\u001b[0m \u001b[39m# function, and first available gradient gets used, in the following order.\u001b[39;00m\n\u001b[0;32m   2169\u001b[0m \u001b[39m# 1. self._gradient_function\u001b[39;00m\n\u001b[0;32m   2170\u001b[0m \u001b[39m# 2. Gradient name registered by \"_gradient_op_type\" attribute.\u001b[39;00m\n\u001b[0;32m   2171\u001b[0m \u001b[39m# 3. Gradient name registered by op.type.\u001b[39;00m\n\u001b[0;32m   2172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_function \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2174\u001b[0m op_def \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_get_op_def(pywrap_tf_session\u001b[39m.\u001b[39;49mTF_OperationOpType(c_op))  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2176\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_stateful \u001b[39m=\u001b[39m op_def\u001b[39m.\u001b[39mis_stateful\n\u001b[0;32m   2178\u001b[0m \u001b[39m# Initialize self._outputs.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Steven Howell\\anaconda3\\envs\\D70\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4205\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   4203\u001b[0m \u001b[39mwith\u001b[39;00m c_api_util\u001b[39m.\u001b[39mtf_buffer() \u001b[39mas\u001b[39;00m buf:\n\u001b[0;32m   4204\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:\n\u001b[1;32m-> 4205\u001b[0m     pywrap_tf_session\u001b[39m.\u001b[39;49mTF_GraphGetOpDef(c_graph, compat\u001b[39m.\u001b[39;49mas_bytes(\u001b[39mtype\u001b[39;49m),\n\u001b[0;32m   4206\u001b[0m                                        buf)\n\u001b[0;32m   4207\u001b[0m   data \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_GetBuffer(buf)\n\u001b[0;32m   4208\u001b[0m op_def \u001b[39m=\u001b[39m op_def_pb2\u001b[39m.\u001b[39mOpDef()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#generator2 = Generator(channel=32)\n",
    "generator2 =  tf.keras.models.load_model('results/model', custom_objects={'loss_function': loss_function})\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "for dataset in test_datasets:\n",
    "    save_path = './results/small/' + dataset + '/'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    image_root = dataset_path + dataset + '/Imgs/'\n",
    "    test_loader = test_dataset(image_root, 352)\n",
    "\n",
    "    for i in range(test_loader.size):\n",
    "        print(i)\n",
    "        image, HH, WW, name = test_loader.load_data()\n",
    "        ans = generator2(image)\n",
    "        fix_image,generator_pred, img2  = tf.unstack(ans,num=3,axis=0)\n",
    "\n",
    "\n",
    "        res = generator_pred\n",
    "        res = tf.image.resize(res, size=tf.constant([WW,HH]), method=tf.image.ResizeMethod.BILINEAR)\n",
    "        res = tf.math.sigmoid(res).numpy().squeeze()\n",
    "        res = 255*(res - res.min()) / (res.max() - res.min() + 1e-8)\n",
    "        \n",
    "        \n",
    "        fix_image = tf.image.resize(fix_image, size=tf.constant([WW,HH]), method=tf.image.ResizeMethod.BILINEAR)\n",
    "        fix_image = tf.math.sigmoid(fix_image).numpy().squeeze()\n",
    "        \n",
    "        fix_image = (fix_image - fix_image.min()) / (fix_image.max() - fix_image.min() + 1e-8)\n",
    "        \n",
    "        res2 = img2\n",
    "        res2 = tf.image.resize(res2, size=tf.constant([WW,HH]), method=tf.image.ResizeMethod.BILINEAR)\n",
    "        res2 = tf.math.sigmoid(res2).numpy().squeeze()\n",
    "        res2 = (res2 - res2.min()) / (res.max() - res2.min() + 1e-8)\n",
    "        '''\n",
    "        fig.add_subplot(1, 3, 1)\n",
    "        \n",
    "        plt.imshow(fix_image)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"First\")\n",
    "        fig.add_subplot(1, 3, 2)\n",
    "        plt.imshow(res)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Second\")\n",
    "        fig.add_subplot(1, 3, 3)\n",
    "        plt.imshow(res2)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Third\")\n",
    "        plt.show()'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253f4ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function: 'loss_function'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#generator2 = Generator(channel=32)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m generator2 \u001b[39m=\u001b[39m  tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39mresults/model2\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m test_datasets:\n\u001b[1;32m      5\u001b[0m     save_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./results/small/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m dataset \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/D70/lib/python3.8/site-packages/keras/saving/saving_api.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m    205\u001b[0m         filepath,\n\u001b[1;32m    206\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[1;32m    207\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[1;32m    208\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[1;32m    209\u001b[0m     )\n\u001b[1;32m    211\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m    213\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39;49mcustom_objects, \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    214\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/D70/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/D70/lib/python3.8/site-packages/keras/saving/legacy/serialization.py:543\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    541\u001b[0m     obj \u001b[39m=\u001b[39m module_objects\u001b[39m.\u001b[39mget(object_name)\n\u001b[1;32m    542\u001b[0m     \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 543\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    544\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown \u001b[39m\u001b[39m{\u001b[39;00mprintable_module_name\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mobject_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPlease ensure you are using a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`keras.utils.custom_object_scope` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mand that this object is included in the scope. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    548\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    549\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m#registering_the_custom_object for details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    550\u001b[0m         )\n\u001b[1;32m    552\u001b[0m \u001b[39m# Classes passed by name are instantiated with no args, functions are\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[39m# returned as-is.\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[39mif\u001b[39;00m tf_inspect\u001b[39m.\u001b[39misclass(obj):\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function: 'loss_function'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdb00c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
